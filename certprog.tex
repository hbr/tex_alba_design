\chapter{Certified Programming}
\label{chap:certprog}


The Alba programming languages makes certain guarantees.
\begin{enumerate}
\item A program cannot crash.

\item There are no endless loops (i.e. the program cannot not freeze).

\item All functions perform according to their specification.
\end{enumerate}

The first point is achieved by a strict typing, a strict handling of pattern
match (all cases must be handled) and the lack of an undisciplined exception
processing. An undisciplined exception processing would be to allow the
throwing of exceptions without enforcement of the handling of exceptional
conditions.

The second point (no endless loops) is achieved by basing all recursions on
some argument which is decreased at each recursive call. This guarantees that
all functions must terminate.

The third point is achieved by implementing the curry howard isomorphism in
the form of propositions as types. It is possible to encode propositions like
$i > 0$ as a type and writing functions which return an inhabitant of these
types i.e. functions which generate a proof of the proposition.

Having this tool, it is possible to state some properties of functions and
prove these properties by writing functions which return proofs of the
desired properties.

In Alba a proof is just a functional programm. A proof of the implication $a
\imp b$ is a function which maps a proof of the proposition $a$ into a proof
of the proposition $b$.

Proofs in Alba are normal objects with the difference that these proof objects
do not exist at runtime. But they are data, which can be arguments to
functions. The functions can iterate over the proof data and can generate
other proof objects.

The purpose of this chapter is to demonstrate the possibility in Alba to write
functions and prove properties about these functions in the same language.




\newpage
\section{Logic}
\label{sec:certprog-logic}


In this chapter we use functional programming to prove some basic laws of
logic. The Alba compiler \emph{knows} how to handle propositions and is able
to do all the proofs in this chapter automatically. You are never required to
produce such proofs by hand.

But is very instructive to see how proofs of these basic laws of logic can be
generated by using functional programming. Therefore we give manual proofs
here.



\subsection{Ex Falso}

\emph{Ex falso quodlibet} i.e. from a false (or contradictory) assumption you
can conclude anything, is a basic law of logic. It is possible to prove this
law in Alba by writing a function with the signature

\begin{alba}
    exFalso (A: Any): false -> A := ...
\end{alba}
%
The signature of this function gives the promise: \emph{Give me an arbitrary
type and a proof of \code{false} and I return you an object of that type}. Since
\code{a:Proposition} implies \code{a:Any} in Alba, all propositions can be
entered as actual arguments for \code{A}.


Remember that \code{false} is an inductive type with the following definition.
\begin{alba}
    class false: Proposition := -- no constructors
\end{alba}
%
Since there are no constructors we can complete the desired function

\begin{alba}
    exFalso (A: Any): false -> A :=
        case
            -- empty pattern match, because there are no constructors
\end{alba}
%
Each case must return an object of the desired type. But since there are no
cases, there is nothing to be done.






\subsection{Negation}

Negation is defined in the prelude as
\begin{alba}
  (not) (a: Proposition): Proposition :=
    a => false
\end{alba}

We want to prove the contrapositive law of logic which states
\begin{alba}
  (a => b) => (not b => not a)
\end{alba}
for all propositions \code{a} and \code{b}. A proof of that fact would be
written in Alba as the function
%
\begin{alba}
  contrapositive (a b: Proposition): (a => b) => not b => not a
  :=
    _      -- '_' means: Compiler, please generate a proof!
\end{alba}
%
It is not necessary to write such a proof by hand, because the compiler can
generate such a proof automatically. But if you want to write the proof
explicitly it looks like

\begin{alba}
    contrapositive (a b: Proposition): (a => b) => not b => not a
    :=
        \ fab notB evA := fab evA |> notB
\end{alba}

\noindent Explanation: A proof of \code{not a} is a function which maps a proof
of \code{a} into a proof of false. If we have a proof of \code{a} we can use the
argument \code{fab} which maps a proof of \code{a} into proof of
\code{b} and then use \code{notB} which maps a proof of \code{b} into a proof
of \code{false} which is the desired result.



Note that in classical logic the two propositions
\begin{alba}
  a  =>  b

  not b => not a
\end{alba}
%
are equivalent. This is not the case in constructive logic on which Alba is
based. Suppose we wanted to prove
%
\begin{alba}
  (not b => not a) => a => b
\end{alba}
%
in Alba. In order to do this we need a function
\begin{alba}
  contra2 a b (p: not b => not a) (pa: a): b :=
     ...
\end{alba}
%
It is not difficult to see that there is no way to generate a proof of \code{b}
by using the arguments. The second argument of the function is atomic i.e. it
is not a function which can be applied. The first argument is a function whose
type we can expand to get
\begin{alba}
  p: (b => false) => a => false
\end{alba}
%
\code{p} is a function with two arguments. There is no way to supply the first
argument. Therefore we cannot use \code{p} and have no possibility to return
an expression of type \code{b}.


However there is a double negation correspondence between classical and
constructive logic. Whenever classical logic is capable to prove \code{a},
constructive logic is capable to prove \code{not not a}. I.e. we should be able
to prove

\begin{alba}
  (not b => not a) => a => not not b
\end{alba}
and define a function with the signature

\begin{alba}
  contra3 (a b: Propositon): (not b => not a) => a => not not b :=
    ...
\end{alba}

Now we have more possibilities because we are no longer required to prove
\code{b} directly, but only to derive \code{false} from \code{not b}. This
opens the possibility to use the function of type \code{not b => not a}.
%
\begin{alba}
    contra3 (a b: Proposition): (not b => not a) => a => not not b
    :=
        \   fNotBNotA evA notB: false :=
                fNotBNotA notB evA
\end{alba}






\subsection{Disjunction}

Logical disjunction is defined in the prelude as the inductive type
%
\begin{alba}
    class
        (or) (a b: Proposition): Proposition
    :=
        left:  a => a or b
        right: b => a or b
\end{alba}
%
i.e. you can either use a proof of \code{a} or a proof of \code{b} to generate
a proof of \code{a or b}.

It is a basic law of logic that \code{a or b} and \code{b or a} are
equivalent, i.e. we should be able to prove
%
\begin{alba}
  a or b  =>  b or a
\end{alba}
%
We prove this fact by defining the corresponding function which pattern
matches on the construction of \code{a or b}
%
\begin{alba}
    swapOr (a b: Proposition): a or b => b or a
    :=
        case
            left pa  := right pa
            right pb := left pb
\end{alba}

\noindent Another law of logic states
\begin{alba}
  a or b  =>  (a => c) => (b => c)  =>  c
\end{alba}
%
i.e. whenever we have a prove of \code{a or b} and are able to conclude
\code{c} from \code{a} and \code{c} from \code{b}, then we are able to
conclude \code{c}.

A function which proves this fact is easy to implement by pattern matching on
the construction of \code{a or b}.

\begin{alba}
    eliminateOr
        (a b c: Proposition)
        :   a or b
            => (a => c)
            => (b => c)
            => c
    :=
        case
            left pa :=
                \ fac _ := fac pa

            right pb :=
                \ _ fbc := fbc pb
\end{alba}










\subsection{Conjunction}

\begin{alba}
    class
        (and) (a b: Proposition): Proposition
    :=
        (,): a => b => a and b
\end{alba}


\begin{alba}
    swapAnd (a b: Proposition): a and b => b and a
    :=
        case
            (pa, pb) := (pb, pa)
\end{alba}


\begin{alba}
    eliminate1And (a b: Proposition): a and b => a :=
        case
            (pa, pb) := pa
\end{alba}








\vskip 5mm
\subsection{De Morgan's Laws}

The De Morgan's Laws are other basic laws of logic. The first of the De
Morgan's laws states the equivalence of the two statements
\begin{alba}
  not (a or b)

  not a and not b
\end{alba}
%
In order to prove the equivalence we have to prove both directions.
\begin{alba}
    deMorgan1Forward
        (a b: Proposition)
        : not (a or b) => not a and not b
    :=
        \ notAOrB :=
            (left >> notAOrB,  right >> notAOrB)
\end{alba}
%
Explanation: \code{notAOrB} is a function which maps evidence of \code{a or b}
into evidence of \code{false}. A proof of \code{not a} needs a function which
maps evidence of \code{a} into evidence of \code{false}. Therefore we can
combine \code{left} which maps evidence of \code{a} into evidence of \code{a or
b} and \code{notAOrB} which maps evidence of \code{a or b} into evidence of
\code{false} and we are done for \code{not a}. The proof of \code{not b} follows
the same pattern.



\begin{alba}
    deMorgan1Backward
        (a b: Proposition)
        : not a and not b => not (a or b)
    :=
        case
            (notA, notB) :=
                case
                    left evA :=
                        notA evA
                    right evB :=
                        notB evB
\end{alba}


There is a second De Morgan's law stating the equivalence of
\begin{alba}
  not a or not b

  not (a and b)
\end{alba}

The forward direction can be proved by the function
\begin{alba}
    deMorgan2Forward
        (a b: Proposition)
        : not a or not b => not (a and b)
    :=
        case
            left notA :=
                case
                    (evA, _) :=
                        notA evA
            right notB :=
                case
                    (_, evB) :=
                        notB evB
\end{alba}


In trying to prove the backward direction we face some difficulties. In order
to prove \code{not a or not b} we have to prove either \code{not a} or
\code{not b}. The only premise we have is \code{not (a and b)} which is a
function mapping any proof of \code{a and b} into \code{false}.

This proof is not possible in constructive logic. Therefore it is not possible
to prove it in Alba either.

In order to prove a disjunction in constructive logic we have to decide which
of the two possibilities of \code{not a or not b} we want to prove. There is
no possibility to make such a decision by looking only at \code{not (a and
  b)}.






\subsection{Predicates and Relations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{alba}
    Predicate (A: Any): Any :=
        A -> Proposition

    Relation (A B: Any): Any :=
        A -> B -> Proposition

    Endorelation (A: Any): Any :=
        Relation A A
\end{alba}






\vskip 5mm
\subsection{Existential Quantification}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The existence of an object with a certain property is expressed in Alba by the
inductive type
%
\begin{alba}
    class
        Exist A (f: Predicate A): Proposition
    create
        witness x: f x -> EXist f
\end{alba}
%
i.e. the existence of an object with a certain property is proved by providing
a witness and a proof that the witness satisfies the required property.

In Alba we write
%
\begin{alba}
  some (x:A): f x

  -- or

  some x: f x   -- if the type 'A' can be inferred from the context
\end{alba}
%
as another way to express the proposition
%
\begin{alba}
  exist f
\end{alba}

A basic law of logic states
%
\begin{alba}
  (some x: f x) => (all x: f x => a) => a
\end{alba}
%
Proofs using this law reads like
\begin{quote}
  We know that there exists an object satisfying $f$. Let $x$ be such an
  object satisfying $f$. From $ f x$ we can conclude $a$. Therefore $a$ is
  valid.
\end{quote}

We can prove this law in Alba by writing the function
\begin{alba}
    exist_elim
        (A: Any)
        (f: Predicate A)
        (prop: Proposition)
        : some x: f x => (all x: f x => prop) => prop
    :=
        \   some_x
            allx
        :=
            inspect some_x case
                witness x fx :=
                    allx x fx
\end{alba}


Like for logical disjunction and conjunction there are two De Morgan's laws for
existential and universal quantification. The first law states the equivalence
of
\begin{alba}
  not (some x: f x)

  all x: not (f x)
\end{alba}
or in words
\begin{quote}
  If there are no objects satisfying a certain property, then all objects do
  not satisfy the property. And if all objects do not satisfy a propert, then
  there are no objects satisfying the property.
\end{quote}

The proofs of the forward and backward direction are not complicated.

\begin{alba}
    ex_de_morgan1_forward
        (A: Any)
        (f: Predicate A)
        : not (some x: f x) => all x: not (f x)
    :=
        \   no_x
            x
            fx
        :=
            no_x (witness x fx)
\end{alba}


\begin{alba}
    ex_de_morgan1_backward
        (A: Any)
        (f: Predicate A)
        : (all x: not (f x)) => not (some x: f x)
    :=
        \   all_not
            some_x
        :=
            inspect some_x case
                witness x fx :=
                    all_not x fx
\end{alba}

The second De Morgan's law states the equivalence of
\begin{alba}
  some x: not (f x)

  not all x: f x
\end{alba}

The forward direction is easy.

\begin{alba}
    ex_de_morgan2_forward
        (A: Any)
        (f: Predicate A)
        : (some x: not (f x)) => not (all x: f x)
    :=
        \   some_x
            all_x
        :=
            inspect some_x case
                witness x not_fx :=
                    not_fx (all_x x)
\end{alba}

However the backward direction is not possible to prove. Constructive logic
requires us to find a witness in order to prove
\begin{alba}
  some x: not (f x)
\end{alba}
%
But the premise
%
\begin{alba}
  not all x: f x
\end{alba}
does not give us any possibility to extract a witness which does not satisfy
the property \code{f}










%-----------------------------------
\section{Specified Types}
%-----------------------------------

In the previous section we defined a function \code{reverse\_prepend} which
should reverse a list and prepend it in front of another list. In a second
step we proved that the function does the expected.

This signals that we might be able to use a specified type (i.e. a type whose
inhabitants satisfy a specification) as a result and implement the function
and the proof of its specification hand in hand.

A specified type is an inductive type of the form
%
\begin{alba}
   class Specified A (f: Predicate A): Any create
     specified x: f x -> Specified f
\end{alba}

The type \code{Specified} is known to the compiler and instead of writing
%
\begin{alba}
  Specified (\ (x:T) := exp)
\end{alba}
%
we can use syntactic sugar and write
%
\begin{alba}
  {x: T : exp}
  -- or
  {x: exp}     -- if the type 'T' can be inferred from the context.
\end{alba}


If we use a specified type in \code{reverse\_prepend} we get the signature
\begin{alba}
  reverse_prepend A (a b: List A): {c: c = a.reverse + b} :=
    ...
\end{alba}

Any implementation of \code{reverse\_prepend} must satisfy the specification
i.e. it has to return a list \code{c} which satisfies
\begin{alba}
  c = a.reverse + b
\end{alba}


The implementation of the function includes the proof of the specification.

\begin{alba}
  reverse_prepend A (a b: List A): {c: c = a.reverse + b} :=
    inspect a case
      [] :=
        specified b where
          _: b = [].reverse + b := _

      h ^ t :=
        inspect t.reverse_prepend (h ^ b) case
          specified c :=
            specified c where
              _: c = (h ^ t).reverse + b :=
                via t.reverse + (h ^ b)      -- hypo
                    t.reverse + ([h] + b)    -- def '+'
                    t.reverse + [h] + b      -- '+' assoc
                    (h ^ t).reverse + b      -- def 'reverse'
\end{alba}


Since the Alba compiler \emph{knows} the mechanics of a specified type, we can
omit one pattern match.

\begin{alba}
  reverse_prepend A (a b: List A): {c: c = a.reverse + b} :=
    inspect a case
      [] :=
        specified b

      h ^ t :=
        t.reverse_prepend (h ^ b) where
          _ c (p: c = t.reverse + (h ^ b))
            : c = (h ^ t).reverse + b :=
             via t.reverse + (h ^ b)      -- 'p'
                 t.reverse + ([h] + b)    -- def '+'
                 t.reverse + [h] + b      -- '+' assoc
                 (h ^ t).reverse + b      -- def 'reverse'
\end{alba}

In this definition we give the compiler a hint on how to transform a proof of
the specification of the recursive call into a proof of the specification of
the outer call.

In the runtime all specifications and proofs are erased. Therefore the
definition of the function \code{reverse\_prepend} in this chapter and the
previous chapter are identical in the runtime.








\section{Ghost Types}
%%%%%%%%%%%%%%%%%%%%%%%%

A ghost type is a computational type downgraded to a proposition.

\begin{alba}
    class
        Ghost (A: Any): Proposition
    :=
        ghost: A -> Ghost A
\end{alba}

Because it is a proposition, its value cannot be used to compute runtime values.
It can be used only to prove other propositions.

Its usefulness has to be checked and discussed.








%-----------------------------------
\section{Equality}
%-----------------------------------



\subsection{Definition and Properties}

Equality is defined in Alba as an inductive type.
\begin{alba}
    class
        Equal {A: Any} (a: A): Predicate A
            -- Note: 'Predicate A' expands to
            --       'A -> Proposition'
    :=
        identical: Equal a a
\end{alba}

Note that the type \code{A} and the object \code{a} are parameters of the
inductive type. The expression \code{(=) a} is a predicate i.e. a function
\code{\textbackslash\ x := a = x} mapping each object \code{x} into the
proposition \code{a = x}.

In the proposition \code{Equal a b} the character of the first argument \code{a}
and the second argument \code{b} is different. The first argument is a parameter
and the second argument is an index.

In general all parameters of an inductive type are implicit arguments of all
constructors. Therefore the type of the constructor \code{identical} is
%
\begin{alba}
    identical {A: Any} {a: A}: Equal a a
\end{alba}
%
The parameters can be inferred from the type \code{Equal a a} which in long form
is \code{Equal A a a}.


The most important property of equality is that it is leibniz equality. This
means that it is not possible to distinguish two equal objects. I.e. for any
type constructor \code{F: A -> Any} we can map any object of type \code{F a} to
an object of type \code{F b}, if \code{a} and \code{b} are equal.

This is interesting if \code{F} is a predicate i.e. \code{F: A -> Proposition}.
Then leibniz equality means that equal objects satisfy the same predicates for
all possible predicates.

\begin{alba}
    leibniz
        {A} {a b: A}
        (eq: Equal a b)
        (F: A -> Any)
        : F a -> F b
    :=
        {- If the two objects 'a' and 'b' are equal then we can map any
           object of type 'F a' to an object of type 'F b' for any type
           constructor 'F'  -}
        inspect eq case
            identical := identity
\end{alba}

The compiler can generate the elimination function automatically for the above
pattern match. The inferred elimination function is
%
\begin{alba}
    \ (b: A) (eq: Equal a b) :=
            -- 'b' is the index, 'eq' is an object of the inductive type.
        F a -> F b
\end{alba}
%
In the match case \code{identical} the index is forced to be identical with the
parameter. Therefore the goal in the match case is \code{F a -> F a} which is
satisfied trivially by the indentity function.




Next we define some more useful functions on equality.
%
\begin{alba}
    applyOnEquals
        {A B: Any} {a b: A}
        (f: A -> B) (eq: Equal a b)
        : Equal (f a) (f b)
    :=
        inspect eq case
            identical := identical

    equalSymmetric
        {A: Any} {a b: A}
        (eq: Equal a b): Equal b a
    :=
        inspect eq case
            identical := identical

    equalTransitive
        {A: Any} {a b c: A}
        (eq: Equal a b)
        : Equal b c -> Equal a c
    :=
        inspect eq case
            identical := identity
\end{alba}


In all cases the compiler is able to generate the elimination function. For the
last definition the compiler generates
%
\begin{alba}
    \ (b: A) (eq: Equal a b) :=
        Equal b c -> Equal a c
\end{alba}
%
In the match case the index \code{b} is forced to be the same as the parameter
\code{a}. Therefore the goal is \code{Equal a c -> Equal a c} which is trivially
satisfied by the identity function.






\newpage


%-----------------------------------
\section{Relations}
\label{sec:certprog-relations}
%-----------------------------------


\subsection{Basic Properties}


In the following we consider endorelations i.e. binary relations where both
domains are the same. For endorelations we can define what it means to be
reflexive, transitive and symmetric.

\begin{alba}
    Reflexive {A:Any} (R: Endorelation A): Proposition :=
        all {a}: R a a

    Irreflexive {A:Any} (R: Endorelation A): Proposition :=
        all {a}: R a a -> False

    Symmetric {A:Any} (R: Endorelation A): Proposition :=
        all {a b}: R a b -> R b a

    Transitive {A:Any} (R: Endorelation A): Proposition :=
        all {a b c}: R a b -> R b c -> R a c

    Antisymmetric {A:Any} (R: Endorelation A): Proposition :=
        all {a b}: R a b -> R b a -> Equal a b

    Connex {A:Any} (R: Endorelation A): Proposition :=
        all {a b}: R a b or R b a

    class
        Preorder {A:Any} (R: Endorelation A): Proposition
    :=
        preorder:
            Reflexive R -> Transitive R -> Equivalence R

    class
        Order {A:Any} (R: Endorelation A): Proposition
    :=
        order:
            Reflexive R -> Transitive R -> Antisymmetric R

    class
        Equivalence {A:Any} (R: Endorelation A): Proposition
    :=
        equivalence:
            Reflexive R -> Transitive R -> Symmetric R -> Equivalence R

    class
        StrictOrder {A: Any} (R: Endorelation A): Proposition
    :=
        strictOrder:
            Irreflexive R -> Transitive R -> StrictOrder R
\end{alba}


A clique is a relation where all elements are related. Trivially a clique is
reflexive, symmetric and transitive.

\begin{alba}
    Clique {A: Any}: Endorelation A :=
        \ a b := True

    cliqueReflexive {A: Any}: Reflexive {A} Clique :=
        -- Theorem: A clique is reflexive.
        \ {a} := trueValid

    cliqueSymmetric {A: Any}: Symmetric {A} Clique :=
        -- Theorem: A clique is symmetric.
        \ {a b} cAB := trueValid

    cliqueTransitive {A: Any}: Transitive {A} Clique :=
        -- Theorem: A clique is transitive.
        \ {a b c} cAB cBC := trueValid
\end{alba}


\subsubsection{Transitive Closure}

Next we define the transitive closure $R^+$ of a relation $R$. Graphically the
construction of $R^+$ from $R$ looks like.

\begin{tikzpicture}
  \node (a0) at (0,0) {$a$};
  \node (b0) at (1,0) {$b$};

  \node (a) at (3,0) {$a$};
  \node (b) at (4,0) {$b$};
  \node (c) at (5,0) {$c$};

  \draw [->,blue] (a0) edge node[above]{$R$} (b0);
  \draw [->,red]
     (a0)
     .. controls (0.25,1) and (0.75,1)
     .. node[above] {$R^+$} (b0);

  \path[->,blue] (a) edge node[above] {$R$} (b);
  \path[->,blue] (b) edge node[above] {$R^+$}    (c);
  \draw[->,red]  (a) .. controls (3.5,1) and (4.5,1) ..  node[above] {$R^+$}  (c);
\end{tikzpicture}


In Alba we write

\begin{alba}
    class
        Plus {A:Any} (R: Endorelation A): Endorelation A
            -- 'Plus R' is the transitive closure of 'R'
    :=
        plusInit {a b}:
            R a b -> Plus R a b
        plusStep {a b c}:
            R a b -> Plus R b c -> Plus R a c
\end{alba}

The definition uses an inductive type. It has two constructors. The
\code{init} constructor allows us to conclude $R^+ a b$ from $R a b$.  The
\code{step} constructor allows us to conclude $R^+ a c$ from $R a b$ and $R^+
b c$.

By intuition we see that the relation $R^+$ is transitive. But in
order to be sure we need a proof. In order to proof transitivity we have to
prove
%
$$
 R^+ a b \imp R^+ b c \imp R^+ a c
$$
%
for all $a$, $b$ and $c$
i.e. we need a function which looks like
%
\begin{alba}
    \ {a b c} (plusAB: Plus R a b) (plusBC: Plus R b c): Plus R a c
    := ...
\end{alba}
%
We can do an induction proof on \code{plusAB: Plus R a b} which generates two
cases.


\begin{alba}
    plusTransitive
        {A: Any} (R: Endorelation A)
        : Transitive (Plus R)
    :=
        \ {a b c} plusAB plusBC :=
            inspect plusAB case
                plusInit rAB :=
                    plusStep rAB plusBC
                plusStep rAX plusXB :=
                    plusStep rAX (plusTransitive R plusXB plusBC)
\end{alba}



\subsubsection{Reflexive Transitive Closure}

In the same manner as the transitive closure we can define the reflexive
transitive closure of a relation.

\begin{tikzpicture}
  \node (reflexive) at (0,0) {$a$};
  \node (a) at (2,0) {$a$};
  \node (b) at (3,0) {$b$};
  \node (c) at (4,0) {$c$};

  \path (reflexive) edge [loop above,red] node {$r^*$} (reflexive);

  \path[->,blue] (a) edge node[above] {$r$} (b);
  \path[->,blue] (b) edge node[above] {$r^*$}    (c);
  \draw[->,red]  (a) .. controls (2.5,1) and (3.5,1) ..  node[above] {$r^*$}  (c);
\end{tikzpicture}

\vbox{
\begin{alba}
    class
        star (A:Any) (r: Endorelation A): Endorelation A
          -- 'r.star' is the reflexive transitive closure of 'r'
    :=
        init a:
           r.star a a

        step a b c:
            r a b
            => r.star b c
            => r.star a c
\end{alba}}

Having the definition we prove that the reflexive transitive closure is
transitive.

\begin{alba}
    star_transitive A (r:Endorelation A): r.star.is_transitive :=
        f a b c (sab: r.star a b) (sbc: r.star b c): r.star a c :=
            inspect
                a; b; sab
            case
                init a :=
                    sbc  -- a = b in this case

                step a x b :=
                    step a x c where
                        hypo: r.star x c := f x b c
\end{alba}



\subsubsection{Equivalence Closure}

It is possible to convert any relation into an equivalence relation.

\begin{tikzpicture}
  \node (a0) at (0,0) {$a$};
  \path (a0) edge [loop above,red] node {$r^\sim$} (a0);

  \node (a1) at (1,0) {$a$};
  \node (b1) at (2,0) {$b$};
  \node (c1) at (3,0) {$c$};
  \draw[->,blue] (a1) edge node[above]{$r$} (b1);
  \draw[->,blue] (b1) edge node[above]{$r^\sim$} (c1);
  \draw[->,red] (a1) .. controls (1.5,1) and (2.5,1) .. node [above]{$r^\sim$} (c1);

  \node (a2) at (4,0) {$a$};
  \node (b2) at (5,0) {$b$};
  \node (c2) at (6,0) {$c$};
  \draw[<-,blue] (a2) edge node[above]{$r$} (b2);
  \draw[->,blue] (b2) edge node[above]{$r^\sim$} (c2);
  \draw[->,red]   (a2) .. controls (4.5,1) and (5.5,1) .. node [above]{$r^\sim$} (c2);
\end{tikzpicture}


\begin{alba}
  class
    equivalence A (r: Endorelation A): Endorelation A
  create
    init a:
     r.equivalence a a

    forward a b c:
      r a b => r.equivalence b c => r.equivalence a b

    backward a b c:
      r b a => r.equivalence b c => r.equivalence a b
\end{alba}


The equivalence closure is transitive.

\begin{alba}
  equivalence_is_transitive
    A (r: Endorelation A)
    : r.equivalence.is_transitive :=
    f a b c ab bc: r.equivalence a c :=
      inspect ab case
        forward a x b :=
          forward a x c where
            xc: r.equivalence x c := f x b c

        backward a x b :=
          backward a x c where
            xc: r.equivalence x c := f x b c
\end{alba}

The equivalence closure is symmetric.

\begin{alba}
  equivalence_is_symmetric
    A (r: Endorelation A)
    : r.equivalence.is_symmetric :=
    f a b ab: r.equivalence b a :=
      inspect ab case
        forward a x b :=   -- i.e. 'r a x' is valid
          equivalence_is_transitive r b x a where
            _: r.equivalence b x := f x b
            _: r.equivalence x a := backward x a a
            _: r.equivalence a a := init a

        backward a x b :=  -- i.e. 'r x a' is valid
          equivalence_is_transitive r b x a where
            _: r.equivalence b x := f x b
            _: r.equivalence x a := forward x a a
            _: r.equivalence a a := init a
\end{alba}






\subsection{Diamonds and Confluence}


A relation is a diamond if it is always possible to join two steps with a
single step.

\begin{alba}
  is_diamond A (r: Endorelation A): Proposition :=
      {:   a  ->  b
           |      |
           v      v
           c  -> some d :}
    all a b c:
      r a b
      => r a c
      => some d: r b d and r c d
\end{alba}


A relation is confluent if its reflexive transitive closure is a diamond.

\begin{alba}
  is_confluent A (r: Endorelation A): Proposition :=
    r.star.is_diamond
\end{alba}



We prove that a diamond relation is confluent. Before doing that, we prove a
stripe lemma.

\begin{alba}
  stripe_lemma
    A
    (r: Endorelation A)
    (rdia: r.is_diamond)
    : all a b c:                       --  a *> b
        r.star a b =>                  --  |    |
        r a c =>                       --  v    v
        some d: r b d                  --  c *> d?
                and
                r.star c d :=
     f a b c sab rac :=
       inspect sab case   -- a = b, therefore we use d = c as witness
         init a :=
           _: some d: r a d and r.star c d  where
             _: r.star c c := init c

         step a x b :=
           {:  a  -> x  *> b
               |     |     |
               v     v     v
               c  -> e? *> d? :}
           _ where
             exist_d: some d: r b d and r.star e d := f x b e
             exist_e: some e: r x e and r c e      := rdia a x c
\end{alba}

Then we can prove that a diamond relation is confluent.

\begin{alba}
  diamond_is_confluent
    A
    (r: Endorelation A)
    (rdia: r.is_diamond)
    : r.is_confluent
    :=
      f a b c sab sac: exist d: r.star b d and r.star c d :=
        inspect sab case
          init a :=            -- a = b, therefore we can use d = c
            _ where            --        as witness
              _: r.star b c := sac
              _: r.star c c := init c

          step a x b :=
            {:  a  ->  x  *>  b
                *      *      *
                v      v      v
                c  ->  e? *>  d? :}
            _ where
              exist_d: some d: r.star b d and r.star e d := f x b e
              exist_e: some e: r.star x e and r c e := stripe_lemma r a c x

\end{alba}



\vskip 5mm
\subsection{Transitivity Proofs}

DRAFT: Work with more implicit arguments. Assumption here: All arguments which
can be inferred by the type checker are implicit.



\begin{alba}
    TransitiveRelation (A: Any): Any :=
        Specified (\ (r: Endorelation A) := isTransitive r)

    class
        TransitiveRelation A
    :=
        makeTransitive
            (relation: Endorelation A)
            (transitive:
                all a b c:
                    relation a b => relation b c => relation a c)

    class
        Path A (r: TransitiveRelation A) (a b: A)
    :=
        makePath: r.relation a b -> Path r a b


    (<+>)
        A (r: TransitiveRelation A) a b c
        (p1: Path r a b)
        (p2: Path r b c):
        Path a c
    :=
        inspect p1 case
            makePath rab :=
                inspect p2 case
                    makePath rbc :=
                        inspect r case
                            makeTransitive rel trans :=
                                makePath
                                    (transitive rab rbc)

\end{alba}












\newpage
\section{Lists}
\label{sec:certprog-lists}


In the following we use the definition of the list type from the prelude.

\begin{alba}
    class
        List (A:Any): Any
    create
        [] : List A
        (::): A -> List A -> List A
\end{alba}


\begin{alba}
    listRecursion
        {A: Any}
        {P: List A -> Any}
        (start: P [])
        (next: all {a lst}: P lst -> P (a :: lst))
        {lst: List A}
        : P lst
    :=
        inspect lst case
            [] :=
                start
            _ :: _ :=
                next (listInduction start next)

    listInduction
        {A: Any}
        {P: Predicate (List A)}
        (start: P [])
        (next: all {a lst}: P lst -> P (a :: lst))
        {lst: List A}
        : P lst
    :=
        inspect lst case
            [] :=
                start
            head :: tail :=
                next (listInduction start next {tail})

    foldLeft {A B: Any} (f: A -> B -> B) (b: B) (lst: List A): B :=
        inspect lst case
            [] :=
                b
            head :: tail :=
                foldLeft f (f head b) tail
\end{alba}


\subsection{Concatenation}


A standard definition of list concatenation looks like

\begin{alba}
  (+) A (a b: List A): List A :=
    inspect a case
      [] :=
        b
      h ^ t :=
        h ^ (t + b)
\end{alba}
Note that the operator $+$ is left associative.


List concatenation is associative
%
\begin{alba}
  sum_associates A (a b c: List A): a + b + c = a + (b + c) :=
    inspect a case
      h ^ t :=
        goal where
          goal: h ^ t + b + c = h ^ t + (b + c) :=
            via
               h ^ t + b + c
               h ^ (t + b + c)      -- def (+)
               h ^ (t + (b + c))    -- hypo
               h ^ t + (b + c)      -- def (+)
          hypo: t + b + c = t + (b + c) :=
            sum_associates t b c
\end{alba}


\begin{alba}
  nil_right_neutral A (a: List A): a + [] = a :=
    inspect a case
      h ^ t :=
        goal where
          goal: h ^ t + [] = h ^ t :=
            via
              h ^ t + []
              h ^ (t + [])   -- def (+)
              h ^ t          -- hypo
          hypo: t + [] = t :=
            nil_right_neutral t
\end{alba}

Instead of writing the recursive function proving this statement explicitly,
we could use a fixpoint instead.

\begin{alba}
  nil_right_neutral: all A (a: List A): a + [] = a :=
    f A a :=
      inspect a case
        h ^ t :=
          goal where
            goal: h ^ t + [] = h ^ t :=
              via
                h ^ t + []
                h ^ (t + [])   -- def (+)
                h ^ t          -- hypo
            hypo: t + [] = t :=
              f t
\end{alba}



\subsection{Reversal}



A simple function to reverse a list looks like

\begin{alba}
  reverse A (a: List A): List A :=
    inspect a case
      [] :=
        []
      h ^ t :=
        reverse t + [h]
\end{alba}


Next we prove a theorem which shows how reversal and concatenation
interact. Specifically we want to prove
\begin{alba}
  (a + b).reverse = b.reverse + a.reverse
\end{alba}

\begin{alba}
  reversal_of_concatenation
    A
    (a b: List A)
    : (a + b).reverse = b.reverse + a.reverse :=
      inspect a case
        h ^ t :=
          goal where
             goal: reverse (h ^ t + b) = reverse b + reverse (h ^ t) :=
               via
                 h ^ (t + b) |> reverse                     -- def '+'
                 h ^ (reverse b + reverse t) |> reverse     -- hypo
                 (b.reverse + t.reverse) + [h]              -- def 'reverse'
                 b.reverse + (t.reverse + [h])              -- '+' assoc
                 b.reverse + (h ^ t).reverse                -- def 'reverse'

             hypo: (t + b).reverse = b.reverse + t.reverse :=
               reversal_of_concatenation t b
\end{alba}


It is intuitively clear, that a double reversal of a list results in the
original list. We prove this property by
%
\begin{alba}
  double_reversal A (a: List A): a.reverse.reverse = a :=
    inspect a case
      h ^ t :=
        goal where
          goal: (h ^ t).reverse.reverse = h ^ t :=
            via
              (t.reverse + [h]).reverse
              [h].reverse + t.reverse.reverse
              [h] + t
          hypo: t.reverse.reverse = t :=
            double_reversal t
\end{alba}



\subsection{Tail Recursion}

Neither concatenation nor reversal are tail recursive. Furthermore definition
of list reversal is rather inefficient because of the $n^2$
complexity. However we can find equivalent functions which are tail recursive
and efficient.

We need an auxiliary function which reverses a list and prepends it in front
of another list.

\begin{alba}
  reverse_prepend A (a b: List A): List A :=
      -- prepend the reversal of 'a' in front of 'b'
    inspect
      a
    case
      [] :=
        b
      h ^ t :=
        t.reverse_prepend (h ^ b)
\end{alba}


We prove that the function does exactly what we are expecting it to do.

\begin{alba}
  reverse_prepend_correct
    A (a b: List A)
    : a.reverse_prepend b = a.reverse + b :=
      inspect a case
        h ^ t :=
          goal where
            goal: (h ^ t).reverse_prepend  b = (h ^ t).reverse + b :=
              via
                t.reverse_prepend (h ^ b)            -- def
                t.reverse + h ^ b                    -- hypo
                t.reverse + ([h] + b)                -- def '+'
                t.reverse + [h] + b                  -- assoc '+'
                (h ^ t).reverse + b                  -- def 'reverse'
             hypo: t.reverse_prepend (h ^ b) = t.reverse + h ^ b :=
               reverse_prepend_correct t (h ^ b)
\end{alba}


It is obvious that
%
\begin{alba}
  a.reverse_prepend [] = a.reverse
\end{alba}
%
is valid which is a direct consequence of the previous theorem. Alba allows to
override a function definition by an equivalent definition. Therefore we can
substitute the inefficient, non-tail-recursive definition of \code{reverse} by
a more efficient and tail recursive version.

\begin{alba}
  reverse A (a: List A): List A :=
    a.reverse_prepend []
\end{alba}

The definition of list concatenation is efficient, but not tail recursive. By
using the proved theorems we see the following equivalence
%
\begin{alba}
  a + b   =  a.reverse.reverse + b
          =  a.reverse.reverse_prepend b
\end{alba}

Using this, we are able to override the definition of list concatenation by a
tail recursive one

\begin{alba}
  (+) A (a b: List A): List A :=
    a.reverse.reverse_prepend b
\end{alba}

Overriding a definition has no effect during compilation. The original
definition remains to analyze properties. However as soon as the compiler
generates executable code, it replaces the original definition by the
definition which overrides the original definition. It is just an optimization
of the runtime.





\section{Natural Numbers}


The type of natural numbers is defined in the prelude inductively.

\begin{alba}
  class Natural :=
    zero: Natural
    add1: Natural -> Natural
\end{alba}

The number $1$ is the constant

\begin{alba}
  one: Natural := zero.add1
\end{alba}

The compiler \emph{knows} of this type and implements it as an efficient
segmented array to represent arbitrary precision arithmetic. Furthermore all
arithmetic functions like addition, multiplication and relational operators
are implemented as efficient functions. But all these builtin functions behave
as the following functions defined recursively on the inductive type above.

Since \code{Natural} is a recursive inductive type, we can write an induction
law for it.

\begin{alba}
    naturalInduction
        {P: Predicate Natural}
        (start: P zero)
        (next: all {i}: P i -> P (add1 i))
        {n: Natural}
        : P n
    :=
        inspect n case
            {\ (i: Natural): Proposition := P i}
            zero: P zero :=
                start
            add1 i: P (add1 i) :=
                next
                    {i}
                    (naturalInduction start next {i}: P i)
\end{alba}

We added the optional elimination function, some type annotations and written
some implicit arguments explicitly to understand the details.





\subsection{Iterators, Recursors and Induction}

\begin{alba}
    recurse {A: Any} (n: Natural) (f: Natural -> A -> A) (start: A): A :=
        naturalInduction
            {\ i := A}
            start
            f
            {n}

    iterate {A: Any} (n: Natural) (f: A -> A) (start: A): A :=
        {- Iterate 'n' times the function 'f' on the start value 'start'.
           Note: The function is tail recursive. -}
        inspect n case
            {\ n := A}
            zero :=
                start
            add1 i :=
                iterate i f (f start)
\end{alba}










\vskip 5mm
\subsection{Arithmetic}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Addition}


First we need addition
\begin{alba}
  (+) (a b: Natural): Natural :=
    inspect a case
      0 :=
        b
      n.add1 :=
        (n + b).add1
\end{alba}

With the iterator we can define addition in another way.

\begin{alba}
    (+) (a b: Natural): Natural :=
        iterate a add1 b
\end{alba}


Addition is associative
%
\begin{alba}
    plusAssociative {a b c: Natural}: Equal (a + b + c) (a + (b + c)) :=
        naturalInduction
            {\ n := Equal (n + b + c) (n + (b + c))}
            identical
            (\ {n} eq := applyOnEquals add1 eq)
            {a}

    -- Note:
    -- applyOnEquals
    --      {A B: Any} {a b: A} (f: A -> B)
    --      : Equal a b -> Equal (f a) (f b)
\end{alba}

In this prove it is necessary to provide the induction predicate explicitly. The
compiler has no idea on which variable we want to do the induction.

We can avoid to provide the induction predicate explicitly by annotating the
induction hypothesis.

\begin{alba}
    plusAssociative {a b c: Natural}: Equal (a + b + c) (a + (b + c)) :=
        naturalInduction
            identical
            (\ {n} (eq: Equal (n + b + c) (n + (b + c))) :=
                applyOnEquals add1 eq)
            {a}
\end{alba}
%
This shows the induction variable explicitly. It is a matter of taste which
variant you prefer. I find the explicit provision of the induction predicate
more readable.


Now we prove that addition is commutative. In order to prove commutativity of
addition we need two lemmas.

\begin{alba}
    zeroRightNeutral (a: Natural): a + zero = a :=
        induce
            {\a := a + zero = a}

            (identical zero)

            (\ n (neutral: n + zero = n :=
                apply add1 neutral)
            a
\end{alba}



\begin{alba}
    pushSuccessor {a b: Natural}: Equal (a + b).add1  (a + add1 b) :=
        naturalInduction
            identical
            (\ {i} eq := apply add1 eq)
            {a}         -- Do induction on 'a'!

    pushSuccessor (a b: Natural): add1 (a + b) = a + add1 b :=
        inspect a case
            zero :=
                identical (add1 b)

            add1 i :=
                -- goal:
                --   add1 (add1 i + b) = add1 i + add1 b
                -- ~>
                --   add1 (add1 (i + b))
                --   = add1 (i + add1 b)
                inject _ _
                    (pushSuccessor i b)
                    add1
\end{alba}



\begin{alba}
    plusCommutes (a b: Natural): a + b = b + a :=
        inspect a case
            zero :=
                -- goal: zero + b = b + zero
                -- reduces to: b = b + zero
                zeroRightNeutral b

            add1 i :=
                -- goal: add1 i + b = b + add1 i
                -- ~>    add1 (i + b) = b + add1 i
                eqTransitive
                    _ _ _
                    (inject _ _ (plusCommutes i b) add1:
                        add1 (i + b) = add1 (b + i))
                    (pushSuccessor b i:
                        add1 (b + i) =  b + add1 i)
\end{alba}







\subsubsection{Multiplication}



Multiplication can be defined as a recursive function as well.

\begin{alba}
  (*) (a b: Natural): Natural :=
    inspect a case
        0 :=
            0
        add1 i :=
            b + i * b
\end{alba}

\begin{alba}
    zeroRightAbsorber (a: Natural): a * zero = zero :=
        inspect a case
            zero :=
                identical zero

            add1 i :=
                -- goal: add1 i * zero = zero
                -- ~>    zero + i * zero = zero
                -- ~>    i * zero = zero
                zeroRightAbsorber i
\end{alba}

By substitution is is evident, that $1$ is the left neutral of
multiplication. The number $1$ is right neutral as well, but this assertion
needs a proof.

\begin{alba}
    oneRightNeutral (a: Natural): a * one = a :=
        inspect a case
            zero :=
                identical zero

            add1 i :=
                -- goal:  add1 i * one = add1 i
                -- ~>     one + i * one = add1 i
                -- ~>     add1 (i * one) = add1 i
                inject _ _
                    (oneRightNeutral i)
                    add1
\end{alba}


The distributivity of multiplication over addition is proved by induction.
%
\begin{alba}
    distributeTimes (a b c: Natural): a * (b + c) = a * b + a * c :=
        inspect a case
            zero :=
                identical zero

            add1 n :=
                -- goal:  add1 n * (b + c)
                --        = add1 n * b + add1 n * c

                -- ~>     (b + c) + n * (b + c)
                --        = (b + n * b) + (c + n * c)
                eqTransitive _ _ _
                    (inject _ _
                        (distributeTimes n b c)
                        (\ x := (b + c) + x)
                        : (b + c) + n * (b + c) = (b + c) + (n * b + n * c))
                    reorder b c (n * b) (n * c)
                where
                    reorder b c x y: (b + c) + x + y = (b + x) + (c + y)
                    :=
                        -- reordering manually is very tedious
                        -- must invent some compiler support
                        ??
\end{alba}

Commutativity of multiplication can be proved by using distributivity.

\begin{alba}
  times_is_commutative (a b: Natural): a * b = b * a :=
    inspect a case
      0 :=
       via 0 * b
           0
           b * 0
       where
         _: b * 0 = 0 := times_zero_is_zero b

      1 + n :=
        via
          (1 + n) * b
          b + n * b
          b + b * n
          b * 1 + b * n
          b * (1 + n)
        where
          hypo: n * b = b * n := times_is_commutative n b
          _: b * 1 + b * n := times_is_distributive b a n
\end{alba}









\subsection{Order Relation}

We define the order relation on natural numbers inductively.

\begin{alba}
    class
        LessEqual: Endorelation Natural
    :=
        init {n}:
            0 <= n

        step {n m}:
            n <= m
            -> LessEqual n.add1 m.add1
\end{alba}
%
Note that in \code{init n} the argument \code{n} is implicit and in \code{step n
m ...} the arguments \code{n m} are implicit.

We can generate an induction law.
\begin{alba}
    leInduction
        {R: Endorelation Natural}
        (ini: all {i}: R 0 i)
        (stp: all {i j}: LessEqual i j -> R i j -> R i.add1 j.add1)
        : all {i j}: LessEqual i j -> R i j
    :=
        \ {i j} le :=
            inspect le case
                init: ini
                step le0 := stp le (leInduction ini stp le0)
\end{alba}

The inductive type has no parameters and two index arguments. The index
arguments are of type \code{Natural}. Therefore the compiler can do some analysis
on the pattern which can constitute the proposition \code{n <= m}

\begin{alba}
        n               m                   constructor

        0               0                   init 0

        0               j.add1              init j.add1

        i.add1          0                   impossible

        i.add1          j.add1              step i j iLEj
\end{alba}
%
Using this analysis the compiler generates the following propositions
\begin{alba}
    discriminate: all n: not LessEqual n.add1 0

    inversion: all n m: LessEqual n.add1 m.add1 -> LessEqual n m
\end{alba}

Let's do the proofs by hand.

\begin{alba}
    -- discriminate and invert via induction law
    discriminate (n: Natural): LessEqual n.add1 zero -> False :=
        leInduction
            {\ n m :=
                inspect n, m case
                    zero, _ :=
                        True
                    add1 i, zero :=
                        False
                    add1 i, add1 j :=
                        True}
            (\ {m} := trueValid)
            (\ {n m} le r := trueValid)


    invert {n m: Natural}
        : LessEqual n.add1 m.add1 -> LessEqual n m
    :=
        leInduction
            {\ n m :=
                inspect n, m case
                    zero, _ :=
                        true
                    add1 i, zero :=
                        true
                    add1 i, add1 j :=
                        LessEqual i j}
            (\ {m} := trueValid)
            (\ {n m} le r := le)


    -- discriminate and invert via pattern match
    discriminate {n: Natural} (le: n.add1 <= 0): false :=
        inspect le case
            -- No case matches.

    invert {n m: Natural} (le: LessEqual n.add1 m.add1): LessEqual n m
    :=
        inspect le case
            -- Init case does not match
            step le := le
\end{alba}



\begin{alba}
    lessEqualZeroIsZero (a: Natural): a <= 0 => a = 0 :=
        inspect a case
            zero :=
                \ le := identical zero
            n.add1 :=
                discriminate {n} >> exFalso
\end{alba}





\noindent The order relation is reflexive i.e. $a \le a$.

\begin{alba}
    lessEqualReflexive {a: Natural}: a <= a :=
        natInduction init step a

    -- Induction predicate
    -- f a := a <= a

    -- 'init' proves 'f zero' i.e. 'zero <= zero'
    -- 'step' proves 'all i: f i -> f i.add1'
    --     i.e. 'i <= i => i.add1 <= i.add1
    --     with implicit argument 'i'
\end{alba}



\noindent Next we prove the law $a \le b \imp a \le 1 + b$.

\begin{alba}
    leImpliesLeSucc
        {a b: Natural}
        :  LessEqual a b  ->  LessEqual a (add1 b)
    :=
        case
            init :=
                init

            step lenm :=
                -- a = n.add1, b = m.add1
                -- goal: n.add1 <= m.add1.add1
                step (leImpliesLeSucc lenm)
\end{alba}











\subsection{Strict Order}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent The strict order relation $<$ is defined as

\begin{alba}
  (<) (a b: Natural): Proposition :=
    add1 a <= b
\end{alba}

Properties:

\begin{alba}
    leToLt (a b: Natural) (le: a <= b): a /= b => a < b :=
        inspect le case
            init b: 0 /= b => 0 < b :=
                inspect b case
                    zero: \ ne := identical zero |> ne |> exFalso
                    add1 i: 0 /= add1 i => 0 < add1 i :=
                        \ ne := step (init i)
            step i j ij
            : add1 i /= add1 j => add1 i < add1 j :=
                \ ne :=
                    step (leToLt ij (ne << apply add1))
\end{alba}


\begin{alba}
    leToNotlt (a b: Natural): a <= b => not b < a :=
        leInduction
            {\ a b := not b < a}
            (\ b := discriminate)
            (\ a b nlt (lt1: b.add1 < a.add1) :=
                inversion lt1 |> nlt)
            a
            b

    ltToNotLe (a b: Natural): a < b => not b <= a :=
        \ lt le :=
            lt |> leToNotLt le
\end{alba}










\vskip 5mm
\subsection{More Order Properties}

\subsubsection{Lower Bounds}

\begin{alba}
    LowerBound (P: Predicate Natural) (a: Natural): Proposition :=
            -- 'a' is a lower bound for all numbers satisfying 'P'
        all {x}: P x -> LessEqual a x

    Least (P: Predicate Natural) (a: Natural): Proposition :=
            -- 'a' is the smallest number satisfying 'p'
        LowerBound P a and P a


    nextLowerBound
        {P: Predicate Natural}
        {n: Natural}
        (lb: LowerBound P n)
        (nfn: not (P n))
        : LowerBound P (add1 n)
    :=
        {- Theorem: If 'n' is a lower bound for the predicate 'P' and 'n'
           does not satisfy 'P', then the add1 of 'n' is a lower bound
           for the predicate 'P' as well. -}
        \ i pi: LessEqual (add1 n) i :=
            inspect n = i case
                left eq :=
                    nfn (leibniz eq P pi)
                right neq :=
                    leToLt lb neq


    lowerBoundTransitive
        {P: Predicate Natural}
        {x y: Natural}
        : LessEqual x y -> LowerBound P y -> LowerBound P x
    :=
        \ leXY lbY {z} pZ :=
            leTransitive leXY (lbY pZ)
\end{alba}






\vskip 5mm
\subsection{Unbounded Search}

In the following we need some common assumptions and definitions which we
bundle within a section.

\begin{alba}
    section
        P: Predicate Natural
        d: Decider P
        e: Exist P
        R: Endorelation Natural :=
            \ x y := x < y and LowerBound P y
    :=
        ...  -- see below
\end{alba}

It is easy to define a function \code{findHelper} which is started with a number
which is guaranteed to be a lower bound of the predicate \code{p}. It checks, if
the start value satisfies the predicate. If yes, it returns the value. If no, it
just increments the start value and continues the search.
%
\begin{alba}
    -- Draft: Termination not guaranteed!!
    findHelper (start: Natural) (lb: LowerBound P start) : Refined (Least P) :=
        inspect d start case
            left startOk :=
                (start, lb, startOk)
            right startNotOk :=
                findHelper  -- illegal recursive call!!
                    start.add1
                    (nextLowerBound lb startNotOk)
\end{alba}
%
Unfortunately this function does not pass the type checker, because none of its
arguments is decreasing at each recursive call. However, if it terminates, it
returns the number with a proof that it is the least number satisfying the
predicate \code{p}.

In order to make the recursive calls structurally decreasing we use the
definition
%
\begin{alba}
    class Terminating (A: Any) (R: Endorelation A): Predicate A :=
        terminate {x}:
            (all {y}: R x y -> Terminating R y)
            -> Terminating R x
\end{alba}
%
where \code{Terminating R x} says that all successors of \code{x} in the
relation \code{R} finally lead to an element which is terminal i.e. which does
not have any successor in \code{R}. The basic idea is to provide the function
\code{findHelper} with an extra argument which is a proof of \code{Terminating R
start} which we can deconstruct at each recursive call.



First we note that all numbers satisfying the predicate \code{P} are terminating
because they do not have any successors in the relation \code{R}.

\begin{alba}
    satToTerminating {x: Natural} (pX: P x): Terminating R x
    {- Theorem: All numbers 'x' which satisfy the predicate 'P' are
       terminating. -}
    :=
        terminate
            (\ {y} rXY :=
                inspect rXY case
                    xLtY * lbY :=
                        {- If 'y' is a lower bound and 'x' satisfies the
                           predicate, then 'y <= x' must be valid. This
                           contradicts 'x < y'. -}
                        leToNotLt (lbY pX) xLtY |> exFalso)
\end{alba}



Now we are going to prove that the predecessor of a terminating number is
terminating as well.

Let's assume that $x + 1$ is terminating. This is possible only if all
successors of $x + 1$ in the relation $R$ are terminating. Remember that a
successor of $x + 1$ in the relation $R$ is a number greater that $x + 1$ which
is a lower bound for the predicate $P$.

We have to prove that all successors $y$ of $x$ in the relation $R$ are
terminating as well i.e. that all $y$ with $x < y$ which are lower bounds for
the predicate $P$ are terminating.

$y$ is either $x + 1$ or a number greater than $x + 1$. If $y$ is $x + 1$ we are
ready, because $x + 1$ is terminating by assumption. If $x + 1 < y$ is valid
then $y$ is a successor of $x + 1$ in the relation $R$ and therefore terminating
by assumption.
%
\begin{alba}
    terminatingToPredecessor
        {x: Natural}
        (tXSucc: Terminating R (add1 x))
        : Terminating R x
    {- Theorem: The predecessor of a terminating number in the relation 'R'
       is terminating. -}
    :=
        inspect tXSucc case
            terminate f :=
                terminate (g f)
        where
            g f: all {y}: R x y -> Terminating R y :=
                \ {y} rXY :=
                    inspect add1 x = y case
                        left xSuccEqY :=
                            leibniz xSuccEqY tXSucc
                        right xSuccNeY :=
                            inspect rXY case
                                ltXY * lbZ :=
                                    f (leToLt ltXY xSuccNeY * lbY)

    terminatingToZero
        : all (n: Natural): Terminating R x -> Terminating R zero
    :=
        naturalInduction
            identitiy
            (\ i f := f <| terminatingToPredecessor i)
\end{alba}

Now it is easy to define the function for unbounded search.

\begin{alba}
    findHelper
        (start: Natural)
        (lb: LowerBound P start)
        (tStart: Terminating R start)
        : Refined (Least P)
    :=
        inspect d start case
            left startOk :=
                (start, lb, startOk)
            right startNotOk :=
                findHelper
                    start.add1
                    nLb
                    (inspect tStart case
                        terminate g :=
                            g (reflexive, nLb))
                where
                    nLb := nextLowerBound lb startNotOk

    find: Refined (Least P) :=
        findHelper
            zero
            (\ i pI := init)
            (inspect e case
                (n, pN) :=
                    terminatingToZero (satToTerminating pN))
\end{alba}

Note that we are in a section. All functions defined in this section use the
assumptions of the section as additional arguments. Therefore the function
\code{find} has the complete signature
%
\begin{alba}
    find
        (P: Predicate Natural) (d: Decider P) (e: Exist P)
        : Refined (Least P)
\end{alba}







\vskip 5mm
\section{Decision Procedure for the Order Relation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



A decision between two alternatives is an inductive type.

\begin{alba}
    class Decision2 (A B: Proposition): Any :=
        left: A  -> Decision2 A B
        right: B -> Decision2 A B

    Decision (A: Proposition): Any :=
        Decision2 A (not A)
\end{alba}



\begin{alba}
    (<=): all (a b: Natural): Decision (LessEqual a b) :=
        \ a :=
            inspect a case
                zero :=
                    left << init
                add1 i :=
                    \ b :=
                        inspect b case
                            {\ b := Decision (LessEqual (add1 i) b)}
                            zero :=
                                right discriminate
                            add1 k :=
                                mapDecision (i <= k)
        where
            mapDecision
                {i j} (d: Decision (LessEqual i j))
                : Decision (LessEqual (add1 i) (add1 j))
            :=
                inspect d case
                    left le0 :=
                        left (step le0)
                    right nle0 :=
                        right (nle0 << invert)
\end{alba}

With advanced pattern match we could write the function more compactly.

\begin{alba}
    (<=) (a b: Natural): Decision (LessEqual a b) :=
        inspect
            a, b
        case
            zero, _ :=
                left << init
            add1 i, zero :=
                right discriminate
            add1 i, add1 j :=
                mapDecision (i <= j)
        where
            mapDecision {i j} (d: Decision (LessEqual i j))
                : Decision (add1 i) (add1 j)
            :=
                ... -- see above
\end{alba}





\vskip 5mm
\section{Search}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{alba}
    Decider (A: Any) (f: Predicate A): Any :=
        all x: Decision (f x)

    class StrongMaybe (A: Any) (f: Predicate A) (a: Proposition): Any :=
        just x: f x -> StrongMaybe f a
        nothing: a -> StrongMaybe f a

    lowerBound (f: Predicate Natural) (n: Natural): Proposition :=
            -- 'n' is a lower bound for all numbers which satisfy 'f'.
        all i: f i => n <= i

    least (f: Predicate Natural) (n: Natural): Proposition :=
            -- 'n' is the least number which satisfies 'f'
        lowerBound f n and f n

    nextLowerBound
        (f: Predicate Natural) (n: Natural)
        (lb: lowerBound f n) (nfn: not (f n))
        : lowerBound f (add1 n)
    :=
        \ i fi: add1 n <= i :=
            inspect n = i case
                left eq :=
                    fi |> leibniz eq nfn
                right neq :=
                    leToLt lb neq

    findBelow
        (f: Predicate Natural)
        (d: Decider f)
        (bound: Natural)
        : StrongMaybe (least f) (lowerBound f bound)
    :=
        search 0 bound (identical bound) (\ i e := init i)
        where
            search
                i k
                (inv1: bound = i + k)
                (inv2: lowerBound f i)
                : StrongMaybe f (lowerBound f i)
            :=
                inspect k case
                    zero :=
                        nothing inv2
                    add1 j :=
                        inspect d i case
                            left sat :=
                                just i (inv2,sat)
                            right notsat :=
                                search
                                    i.add1
                                    j
                                    (leibniz
                                        {(=) bound}
                                        inv1
                                        (pushSuccessor {i} {j} |> flip)
                                    (nextLowerBound inv2 notsat)
\end{alba}


Now we want to implement a search for the least number which satisfies a
certain predicate under the assumption that such a number exists.

Since we have no search bound, we cannot use a recursive function which reduces
one of its arguments on each recursive call. On the contrary, as long as we have
not yet found the number we have to increase the number by one and call the
recursive function with the increased argument. I.e. we need some other
inductive object which we can decrease on each recursive call.

\begin{alba}
    class terminating (A: Any) (r: Endorelation A) (x: A): Proposition :=
        terminate: (all y: r x y -> terminating r y) -> terminating r x
\end{alba}


\begin{alba}
    searchRelation (p: Predicate Natural): Endorelation Natural :=
        \ x y := x < y and lowerBound p y
\end{alba}


\begin{alba}
    findHelper
        (f: Predicate Natural)
        (d: Decider f)
        (start: Natural)
        (lb: lowerBound f start)
        (term: terminating (searchRelation f) start)
        : Refined (least f)
    :=
        inspect d start case
            left startOk :=
                (start, (lb, startOk))
            right notStartOk :=
                findHelper
                    d
                    start.add1
                    (inspect term case
                        terminate g :=
                            g (reflexive, nextLowerBound f lb notStartOk))


    find
        (f: Predicate Natural)
        (d: Decider f)
        (e: exist f)        -- There is some number satisfying 'f'
        : Refined (least f)
    :=
        search zero ???
        MISSING
\end{alba}



\vskip 5mm
\section{Properties of Constructors of Inductive Types}

There are two properties of constructors of inductive types which are very
important and valid for all inductive types.

\begin{enumerate}

\item Constructors are unique: Objects constructed by
different constructors are different.

\item Constructors are injective: Equal objects constructed by the same
constructor must have been constructed by applying the constructor to the same
arguments.

\end{enumerate}

We prove these properties for natural numbers. The proofs for other constructors
of other inductive types follow the same pattern.




\subsection{Uniqueness of Constructors}

In order to prove the uniqueness of the constructors of natural numbers we have
to prove the proposition

\begin{alba}
    all (n: Natural): 0 /= n.add1
\end{alba}

Remember that \code{0 /= n.add1} is equivalent to \code{0 = n.add1 =>
false}. In order to prove the property we have to find a function which
maps any natural number \code{n} and a proof of \code{0 = n.add1} into a
proof of \code{false}.

Since we can assume \code{0 = n.add1} we can use the leibniz property that
\code{0} and \code{n.add1} satisfy the same predicates. If we find a
predicate over natural numbers which we can prove for \code{0} we can use the
leibniz rule to prove that \code{n.add1} satisfies the same predicate.

We use the predicate
\begin{alba}
    f: Natural -> Proposition :=
        case
            0 :=
                true
            k.add1 :=
                false
\end{alba}

Evidently \code{f 0} and \code{true} are equivalent propositions and \code{f
n.add1} and \code{false} are equivalent propositions.

A proof of \code{f 0} i.e. \code{true} is trivial, because the proposition
\code{true} is an inductive type with one constructor.

\begin{alba}
    class true: Proposition := trueValid
\end{alba}


Here is the complete proof of the mutual exclusivity of the two constructors of
natural numbers.


\begin{alba}
    discriminate (n: Natural): 0 /= n.add1
    :=
        (\ (eq: 0 = n.add1): false := g n.add1 eq)
        where
            g: all k: 0 = k => f k :=
                case
                    identical :=
                        -- goal: f 0
                        trueValid
            f :=
                case 0 := true; k.add1 := false
\end{alba}


There is an alternative way to write \code{discriminate} with an elimination
function

\begin{alba}
    discriminate (n: Natural): 0 /= n.add1 :=
        \ (eq: 0 = n.add1) :=
            inspect
                n.add1     -- index (optional, can be ommitted)
                eq              -- inductive object
            case
                {\ i p :=
                    inspect i case
                        zero := true
                        add1 k := false}
                identical := trueValid
\end{alba}

Instead of \code{true} we could use \code{all (A: Proposition):A -> A} and
prove it by \code{\mybackslash\ A x := x} instead of \code{trueValid}.




\subsection{Injectivity of Constructors}

The injectivity of the add1 function of natural numbers can be expressed
by the property

\begin{alba}
    all (n m: Natural): n.add1 = m.add1  =>  n = m
\end{alba}

In order to prove this property we need only a little trick. We have to
express the goal \code{n = m} as a function of variable representing the right
hand side of the premise equality which returns the required goal, when
instantiated with \code{m.add1}. It might not be trivial to find such a
function, but it is easy to see that the following function does the job.

\begin{alba}
    f: Natural -> Proposition :=
        case 0 :=
                true
             i.add1 :=
                n = i
\end{alba}
%
Having that function the actual proof is a straightforward pattern match on the
premise equality.


\begin{alba}
    invert (n m: Natural) (eq: n.add1 = m.add1): n = m
    :=
        g m.add1 eq
        where
            g: all k: n.add1 = k => f k :=
                case identical :=
                    -- goal f n.add1
                    identical
            f :=
                case
                    0 :=
                        true -- never used
                    i.add1 :=
                        n = i
\end{alba}


We can write \code{invert} as well with an elimination function

\begin{alba}
    invert (n m: Natural) (eq: n.add1 = m.add1): n = m :=
        inspect
            m.add1
            eq
        case
            {\ i p :=
                inspect i case
                    zero :=
                        true -- not used
                    add1 m :=
                        n = m}
            identical :=
                identical n
\end{alba}

Note that for the matching case the elimination function is called with the
arguments \code{n.add1} and \code{eq} and returns \code{n=n}.  This is
correctly proved by \code{identical n}.

However for the whole pattern match the elimination function is called with the
arguments \code{m.add1} and \code{eq} and returns \code{n = m}. I.e. the
whole inspect expression returns a proof of \code{n = m}.







\subsection{Types with Indices}

Consider the inductive predicate

\begin{alba}
    class
        isEven: Predicate Natural
    :=
        zero: isEven 0
        next: all n: isEven n => isEven n.add1.add1
\end{alba}

The proposition \code{isEven 0} can be constructed only with the first
constructor. The proposition \code{isEven k.add1.add1} can be
constructed only with the second constructor. We can make a further case split
on \code{k}.  \code{isEven 0.add1} is impossible to construct and
\code{isEven n.add1.add1} implies \code{isEven n}.

I.e. we should be able to prove the following propositions:

\begin{alba}
    discriminate: not 0.add1.isEven

    invert: all n: isEven n.add1.add1 => isEven n
\end{alba}


\noindent First we prove \code{discriminate}
%
\begin{alba}
    discriminate: not 0.add1.isEven
    :=
        g 0.add1
        where
            g: all k: k.isEven => f k :=
                case
                    zero :=
                        -- goal: f 0
                        trueValid
                    next n evN :=
                        -- goal: f n.add1.add1
                        trueValid
            f: Predicate Natural :=
                case
                    0 :=
                        true
                    m.add1 :=
                        inspect m case
                            0 :=
                                false
                            _.add1 :=
                                true
\end{alba}




\noindent Now we prove \code{invert}
%
\begin{alba}
    invert (n: Natural): n.add1.add1.isEven => n.isEven
    :=
        g n.sucessor.add1
        where
            g: all k: k.isEven => f k :=
                case
                    zero :=
                        -- goal: f 0
                        trueValid
                    next m evM :=
                        -- goal: f m.add1.add1
                        evM
            f: Predicate Natural :=
                case
                    0 :=
                        true
                    k.add1 :=
                        inspect k case
                            0 :=
                                true -- never used
                            m.add1 :=
                                m.isEven
\end{alba}




\noindent NEEDS REWORK WITH NEW DEPENDENT PATTERN MATCH

These proofs create a lot of overhead. Some compiler support shall be available
to them in a simpler manner.

First let's look at the proof of
\begin{alba}
    discriminate: isEven 0.add1 => false :=
        case ...
\end{alba}
The pattern matches a proof of \code{isEven 0.add1} against the two
possible constructors
\begin{alba}
    zero: isEven 0
    next n: isEven n => isEven n.add1.add1
\end{alba}
First the compiler tries to the premise with the final types of the
constructors.
\begin{alba}
    -- Needed unifications
    isEven 0.add1              isEven 0
    isEven 0.add1              isEven n.add1.add1
\end{alba}
Both unifications fail. I.e. a proof of \code{isEven 0.add1} cannot be
generated by none of the two constructors. Note that a failure of the
unification always comes from a failure to unify the indices. \code{isEven} is
an indexed type, indexed by a natural number. The failure to unify comes from
the fact, that the typed to be pattern matched has indices which are not
variables.

Since both unifications fail, both branches can be ommitted from the source code
and the compiler can generate the cases internally. In order to do that, it has
to generate a proper elimination function. An elimination function for an
indexed inductive type $T$ has the form
$$
    \lambda \ybold^\Bbold x^{T \ybold}. R
$$
It has $n + 1$ arguments where $n$ is the number of indices. $\ybold$ is the
array of indices and $x$ is a bound variable representing the expression to be
pattern matched on.

In our case the argument $x$ is irrelevant. The elimination function has to
return the goal \code{false} for the index argument \code{0.add1} and
something with a trivial proof for all the other cases (e.g. \code{goal -> goal}
which is provable by the identity function. As long as primitive values of an
inductive type are involved, such a elimination function can be generated by the
compiler in case of a failed unification.

The type checker is happy, because it has for each case a term is of the
appropriate type for the branch and the overall goal is satisfied as well.

A complete pedantic proof with an explicitely entered elimnation function looks
like
\begin{alba}
    discriminate isEven 0.add1 => false :=
        \ ev := g 0 ev where
            g k ev :=
                inspect
                    ev
                    \ j p := inspect j case
                        0 := false => false
                        m.succ :=
                            inspect m case
                                0 := false
                                n.succ := false => false
                case
                    zero :=
                        identity
                    next i p :=
                        identity
\end{alba}
But the shorter one should do its job as well.
\begin{alba}
    discriminate isEven 0.add1 => false :=
        case --  <--- no valid cases to analyze
\end{alba}

\vskip 5mm
Now let's look at the proof of

\begin{alba}
    inversion k: isEven k.add1.add1 => isEven k :=
        case ...

    -- needed unifications
    isEven k.add1.add1        isEven 0
    isEven k.add1.add1        isEven n.add1.add1
\end{alba}
The first one fails and the second one unifies $k$ with $n$.




\vskip 5mm
Now let's look at a definition of the even and odd property of natural numbers
defined as a mutual type family.
%
\begin{alba}
    mutual
        class
            isEven: Natural -> Proposition
        :=
            zero: isEven 0

            fromOdd n: n.isOdd => n.add1.isEven

        class
            isOdd: Natural -> Proposition
        :=
            fromEven n: n.isEven => n.add1.isOdd
\end{alba}
%
Looking at the possible ways to construct the even or the odd property we should
be able to proof the following theorems.
%
\begin{alba}
    discriminate: not 0.isOdd

    invertEven n: n.add1.isEven => n.isOdd

    invertOdd  n: n.add1.isOdd  => n.isEven
\end{alba}


\noindent We prove the properties one by one.

\begin{alba}
    discriminate: not 0.isOdd :=
        (\ odd := f 0 odd identical)
        where
        f n: n.isOdd => 0 = n => false
        :=
            case
                fromEven k _ :=
                    -- goal: 0 = k.add1 => false
                    discriminate

    invertEven n: n.add1.isEven => n.isOdd
    :=
        (\ ev := f n.add1 ev identical)
        where
        f k: k.isEven => k = n.add1 => n.isOdd
        :=
            case
                zero :=
                    -- goal 0 = n.add1 => false
                    discriminate n

                fromOdd m mOdd :=
                    -- goal: m.add1 = n.add1 => n.isOdd
                    invert m n -- produces m = n
                    >>
                    case
                        identical := mOdd

    invertOdd n: n.add1.isOdd => n.isEven
    :=
        (\ odd := f n.add1 odd identical)
        where
        f k: k.isOdd => k = n.add1 => n.isEven
        :=
            case
                fromEven m mEven :=
                    -- goal: m.add1 = n.add1 => n.isEven
                    invert m n -- produces m = n
                    >>
                    case
                        identical := mEven
\end{alba}

The trick to prove these kind of properties is always the same. Whenever we have
a goal or a premise of a special form like \code{0.isOdd} or
\code{m.add1.isOdd} we replace the special term by a variable to get
\code{n.isOdd} and introduce an equality like \code{0 = n} or \code{n =
m.add1} to have an equivalent formulation.

With the variable we can do a pattern match and use a further pattern match on
the corresponding equality or a discrimination to prove the goal.

Once the trick has been understood, it is a fairly mechanical excercise. Since
this a repetitive task for all newly defined inductive propositions, it is
better to let the compiler derive the corresponding inversion and discrimination
properties.



\subsection{Compiler Generated Proofs Involving Constructors}



\begin{alba}
    reject (n: Natural): 0 = n.add1 => false
    :=
        (\ k :=
            (case identical := trueValid)
            : 0 = k
              =>
              (case 0 := true; _.add1 := false) k)
          n.add1
\end{alba}


\begin{alba}
\end{alba}





\section{Vectors}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


FOR DISCUSSION!!


Vectors or length indexed lists are an often used example to show dependent
types. A vector in Alba can be defined as

\begin{alba}
    class
        Vector (A: Any): Natural -> Any
    :=
        nil: Vector A 0

        cons: all n: A -> Vector A n -> Vector A n.add1
\end{alba}

A companion type for indices into a vector is the following type

\begin{alba}
    class
        Below: Natural -> Any
    :=
        belowStart {k} -> Below (add1 k)
        belowNext {k}: Below k -> Below (add1 k)
\end{alba}


We can savely retrieve the $i$-th element of a vector

\begin{alba}
    getElement {A: Any} {n: Natural} (i: Below n) (v: Vector A n): A :=
        inspect
            i, v
        case
            belowStart, cons x v :=
                x
            belowNext j, cons x v :=
                getElement j v
        -- Note: Other cases are not possible!!
\end{alba}

We can append two vectors.

\begin{alba}
    append
        {A: Any} {n m: Natural}:
        Vector A n -> Vector A m -> Vector A (n + m)
    :=
        case
            nil :=
                identity

            cons x a :=
                \b :=
                    cons x <| append a b
                -- or in pointless notation
                cons x << append a
\end{alba}


\begin{alba}
    reverse {A: Any} {n: Natural} (v: Vector A n): Vector A n
    :=
        inspect v case
            nil := nil
            cons x w := append (reverse w) (cons x nil)

    -- Note: This function does not typecheck. The append function returns
    --       an object of type 'Vector A (k + add1 0)' while it
    --       should return an object of type 'Vector A (add1 0 + k)'
    -- A proof would be necessary to show that both types are identical.
\end{alba}







\section{Red Black Trees}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Ideas from Stephanie Weyrich's Haskell implementation:

\begin{alba}
    class Color := red; black

    class height: Proposition := zero: height; succ: height -> height


    incr (c: Color) (h: height): height :=
        inspect c case
            red := h
            black := succ h

    class
        RBT A: Color -> height -> Any
    :=
        nil: RBT A black zero

        tr h c1 c2: RBT A c1 h -> A -> RBT A c2 h -> RBT A black (succ h)

        tb h: RBT A black h -> A -> RBT A black h -> RBT A red h


    class
        Almost A: height -> Any
    :=
        almost h c1 c2 c: RBT c1 h -> A -> RBT c2 h -> Almost (incr c h)

    class
        Hidden A: height -> Any
    :=
        hr h: RBT red h -> Hidden h

        hb h: RBT black (succ h) -> Hidden (succ h)
\end{alba}











%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main_alba_design"
%%% End:
